{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Class Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['id', 'url', 'landmark_id'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# dataset = pd.read_csv('./data/train.csv') # Gede's import\n",
    "dataset = pd.read_csv(\"./data/recognition/train.csv\") # Basil's import\n",
    "print(dataset.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Images expected (Training): 1225029\n",
      "Number of Images downloaded (Training): 1225027\n",
      "Difference: 2\n",
      "Missing Images:\n",
      "id                                              10f06455b6a05d88\n",
      "url            http://celebhot.hol.es/picture/static.panorami...\n",
      "landmark_id                                                12914\n",
      "Name: 723431, dtype: object\n",
      "id                                              92423ea7db8ff3af\n",
      "url            http://r2.bru02t11.c.bigcache.googleapis.com/s...\n",
      "landmark_id                                                10895\n",
      "Name: 792934, dtype: object\n"
     ]
    }
   ],
   "source": [
    "dir = \"/run/media/dekatria/My Passport/kaggle_dataset/google_recognition/train/\" # Basil's import\n",
    "imgList = os.listdir(dir) \n",
    "\n",
    "print(\"Number of Images expected (Training): %s\" % (dataset.shape[0]))\n",
    "print(\"Number of Images downloaded (Training): %s\" % len(imgList))\n",
    "print(\"Difference: %s\" % (dataset.shape[0] - len(imgList)))\n",
    "\n",
    "print(\"Missing Images:\")\n",
    "expImgList = [\"%s.jpg\" % x for x in range(dataset.shape[0])]\n",
    "    \n",
    "for i in list(set(expImgList)-set(imgList)):\n",
    "    ind = int(i[:-4])\n",
    "    print(dataset.iloc[ind])\n",
    "dataset = dataset.drop(dataset.index[ind])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgDim = []\n",
    "for i in imgList:\n",
    "    try:\n",
    "        img = Image.open(dir + i)\n",
    "        imgDim.append(img.size)\n",
    "    except:\n",
    "        imgDim.append((\"NA\",\"NA\"))\n",
    "print(imgDim[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting instance count of each class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum: 50337\n",
      "Mean: 81.93625844425122\n",
      "No. classes: 14951\n",
      "\n",
      "Filtering classes with count > 80\n",
      "Mean: 413 images per class\n",
      "No. valid classes: 2421\n",
      "\n",
      "Filtering classes with count > 40\n",
      "Mean: 270 images per class\n",
      "No. valid classes: 4040\n",
      "\n",
      "Filtering classes with count > 20\n",
      "Mean: 187 images per class\n",
      "No. valid classes: 6154\n"
     ]
    }
   ],
   "source": [
    "data_freq = dataset.groupby('landmark_id').size().reset_index(name='counts')\n",
    "print('Maximum:', data_freq['counts'].max())\n",
    "print('Mean:', data_freq['counts'].mean())\n",
    "print('No. classes:', len(data_freq))\n",
    "\n",
    "print('\\nFiltering classes with count > 80')\n",
    "data_freq_upper = data_freq[data_freq['counts'] > 80]\n",
    "print('Mean:', int(data_freq_upper['counts'].mean()), 'images per class')\n",
    "print('No. valid classes:', len(data_freq_upper))\n",
    "\n",
    "print('\\nFiltering classes with count > 40')\n",
    "data_freq_upper2 = data_freq[data_freq['counts'] > 40]\n",
    "print('Mean:', int(data_freq_upper2['counts'].mean()), 'images per class')\n",
    "print('No. valid classes:', len(data_freq_upper2))\n",
    "\n",
    "print('\\nFiltering classes with count > 20')\n",
    "data_freq_upper3 = data_freq[data_freq['counts'] > 20]\n",
    "print('Mean:', int(data_freq_upper3['counts'].mean()), 'images per class')\n",
    "print('No. valid classes:', len(data_freq_upper3))\n",
    "\n",
    "# print(data_freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# saving stuff\n",
    "data80_filter = data_freq_upper['landmark_id']\n",
    "dataset80 = dataset[dataset['landmark_id'].isin(data80_filter)]\n",
    "dataset80.to_csv(\"./data/train80.csv\")\n",
    "\n",
    "\n",
    "data40_filter = data_freq_upper2['landmark_id']\n",
    "dataset40 = dataset[dataset['landmark_id'].isin(data40_filter)]\n",
    "dataset40.to_csv(\"./data/train40.csv\")\n",
    "\n",
    "data20_filter = data_freq_upper['landmark_id']\n",
    "dataset20 = dataset[dataset['landmark_id'].isin(data20_filter)]\n",
    "dataset20.to_csv(\"./data/train20.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
